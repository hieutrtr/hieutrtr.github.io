---
layout: post
title: "From Context Anxiety to Context-Aware Engineering"
description: "How context-aware loops turn large language model limitations into reliable agent design patterns."
featured: false
lang: en
ref: context-aware-engineering
permalink: /context-aware-engineering/
banner: /assets/images/context-anxiety-banner.svg
banner_alt: "Illustration of a glowing brain surrounded by signal waves and a DNA helix"
date: 2025-10-05
---

# ğŸ§  From Context Anxiety to Context-Aware Engineering

Turning LLM Limits into a Practical Design Pattern

_(Inspired by Cognitionâ€™s Devin and Anthropicâ€™s Sonnet 4.5)_

> How two engineering blogs from late 2025 quietly defined a new discipline for building long-horizon AI agents.

---

## ğŸ—ï¸ Abstract

Even with context windows approaching a million tokens, large language models (LLMs) still struggle when their attention budget fills up.
Two key engineering posts published in Septâ€“Oct 2025 â€”

- **Anthropic** â€” â€œEffective Context Engineering for AI Agentsâ€ (Sept 2025)
- **Cognition AI** â€” â€œRebuilding Devin for Sonnet 4.5: Lessons and Challengesâ€ (Oct 2025)

â€” both revealed a consistent pattern: LLMs like Sonnet 4.5 start summarizing, externalizing notes, and closing tasks early when they think theyâ€™re near the edge of their context window.

That behavior, nicknamed **context anxiety**, turns out to be more feature than bug â€” if you know how to design around it.

---

## 1ï¸âƒ£ The Observation: Context Anxiety & Underestimation

From Cognition AIâ€™s field tests with Devin:

- Sonnet 4.5 acts as if it knows when memory is running low â€” but it underestimates remaining space.
- This causes premature summarization and early task termination.
- It even starts writing files like `SUMMARY.md` or `CHANGELOG.md` to dump thoughts externally.

Cognition added both start- and end-of-prompt reminders:

> â€œDonâ€™t summarize until youâ€™ve completed all acceptance checks.â€

A trick that helped: enabling 1 M-token mode but capping at â‰ˆ 200 K, giving the model the impression of more headroom.

These behaviors match Anthropicâ€™s warning that adding more tokens doesnâ€™t always help â€” LLMs degrade once the signal-to-noise per token drops.

---

## 2ï¸âƒ£ The Idea: Treat Anxiety as a Signal, Not a Bug

When an LLM starts summarizing, thatâ€™s a heartbeat.
Instead of ignoring it, an orchestrator can listen to that signal and trigger a new loop:

1. **Checkpoint** â€“ capture the current reasoning state.
2. **Compact** â€“ summarize key knowledge into structured memory.
3. **Re-seed** â€“ start a new, focused reasoning episode (a sub-context).

This turns context limits into natural milestones instead of silent failure points.

---

## 3ï¸âƒ£ What Is a Sub-Context?

A sub-context is a bounded reasoning sandbox: one coherent module inside a larger project.

| Sub-Context | Purpose | Example Tokens |
|-------------|---------|----------------|
| `auth_module` | Build login flow | 20 K |
| `test_module` | Write tests | 15 K |
| `docs_module` | Generate API docs | 8 K |

Each sub-context starts with a structured summary seed (goals, decisions, blockers), runs a short burst of reasoning, and produces a new summary for the next stage.
Think of it as chunked cognition with continuity.

---

## 4ï¸âƒ£ A Context-Aware Loop

```python
# simplified orchestrator control loop
if remaining_tokens() <= SOFT_THRESHOLD \
   or detects_summary_behavior(model_output) \
   or file_write("SUMMARY.md"):
    checkpoint()
    compact_context()
    persist_state()
    start_new_subcontext()
else:
    continue_work()
```

âœ… `SOFT_THRESHOLD â‰ˆ 20 %` of the modelâ€™s context window â†’ leaves headroom to offset Sonnetâ€™s tendency to underestimate available tokens.

---

## 5ï¸âƒ£ Structured Summaries = Machine-Readable Memory

Free-form notes are fragile. Use schemas instead:

```yaml
summary:
  module: "UserAuth"
  goal: "Implement login flow"
  decisions:
    - "Use bcrypt for hashing"
  artifacts:
    - "auth/login.js"
  blockers:
    - "Add tests for refresh tokens"
  next_steps:
    - step: "Write test_login_refresh()"
      acceptance: "All tests pass"
```

Store this externally (database, object store, or vector memory).
Next sub-context loads only these compact fields â€” never the full transcript.

---

## 6ï¸âƒ£ Spawning the Next Sub-Context

Seed each new context with:

- **Background:** previous goals, decisions, blockers.
- **Instructions:** next actions + acceptance criteria.
- **Retrieval handles:** file paths or issue IDs, not raw blobs.

```xml
<background>
Youâ€™re resuming work on {{module}}.
Past decisions: {{decisions}}
Outstanding blockers: {{blockers}}
</background>

<instructions>
Execute {{next_steps}}.
Fetch details via tools when needed.
Summarize only after acceptance checks pass.
</instructions>
```

---

## 7ï¸âƒ£ Periodic Heartbeats

Ask the model to emit a light JSON status:

```json
{"heartbeat":{
  "phase":"normal|summarizing|wrapping_up",
  "estimated_remaining_tokens":900,
  "new_files":["SUMMARY.md"]
}}
```

When `phase == "summarizing"`, trigger a checkpoint and start a new sub-context.

---

## 8ï¸âƒ£ Why This Pattern Works

| Without Management | With Context-Aware Loop |
|--------------------|-------------------------|
| Random early summaries | Predictable checkpoints |
| Context overflow | Controlled resets |
| Lost reasoning chain | Structured memory continuity |
| Token waste | Stable multi-hour sessions |

It converts the modelâ€™s â€œstress responseâ€ into a reliable feedback loop.

---

## ğŸ”§ Developer Checklist

- âœ… Monitor token usage per turn
- âœ… Trigger checkpoint â‰¤ 20 % remaining
- âœ… Detect summary phrases / note-file writes
- âœ… Persist structured YAML/JSON summaries
- âœ… Re-seed minimal sub-contexts
- âœ… Insert start + end reminders to fight premature wrap-ups

---

## âš ï¸ Sources & Credit

- Cognition AI, _Rebuilding Devin for Sonnet 4.5: Lessons and Challenges_, Oct 2025
- Anthropic, _Effective Context Engineering for AI Agents_, Sept 2025

This article re-expresses their insights as a reproducible engineering pattern, not as proprietary implementation details.

---

## ğŸ§­ Final Thought

> â€œEvery token is precious.â€ â€” Anthropic

When your model starts summarizing, itâ€™s not panicking â€” itâ€™s signaling.
Listen, checkpoint, and let it breathe.
Thatâ€™s how context anxiety becomes context awareness.

---

**Tags:** #AIEngineering #LLMAgents #ContextWindow #Anthropic #CognitionAI #Devin #PromptEngineering

